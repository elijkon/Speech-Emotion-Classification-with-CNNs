{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elijkon/Speech-Emotion-Classification-with-CNNs/blob/main/DL_miniHackathon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "MtXtcriegXyy"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Elijah Konkle, Kritan, and Mayur\n",
        "Deep learning minihackathon\n",
        "\n",
        "Each of the 1440 files has a unique filename. The filename consists of a 7-part numerical identifier (e.g., 03-01-06-01-02-01-12.wav). These identifiers define the stimulus characteristics:\n",
        "\n",
        "Filename identifiers\n",
        "\n",
        "1) Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
        "\n",
        "2) Vocal channel (01 = speech, 02 = song).\n",
        "\n",
        "3) Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
        "\n",
        "4) Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
        "\n",
        "5) Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
        "\n",
        "6) Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
        "\n",
        "7) Actor (01 to 24. Odd numbered actors are male, even numbered actors are female).\n",
        "\n",
        "Filename example: 03-01-06-01-02-01-12.wav\n",
        "\n",
        "Audio-only (03)\n",
        "Speech (01)\n",
        "Fearful (06)\n",
        "Normal intensity (01)\n",
        "Statement \"dogs\" (02)\n",
        "1st Repetition (01)\n",
        "12th Actor (12)\n",
        "Female, as the actor ID number is even.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "TpqIm7MBXbQD"
      },
      "outputs": [],
      "source": [
        "# 1. Install deps (if not already installed)\n",
        "!pip install datasets torch torchvision\n",
        "\n",
        "# 2. Import libraries\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import wandb\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bqNgrNo5jd8s"
      },
      "outputs": [],
      "source": [
        "\n",
        "from datasets import load_dataset\n",
        "from google.colab import userdata\n",
        "HF_Token = userdata.get('HF_TOKEN')\n",
        "from huggingface_hub import login\n",
        "if HF_Token:\n",
        "  login(token=HF_Token)\n",
        "  print(\"Successfully logged in to Hugging Face!\")\n",
        "else:\n",
        "  print(\"HF_TOKEN secret not found. Please add it to Colab Secrets.\")\n",
        "dataset = load_dataset(\"elijkon/DL_Spectrograms\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lMtJd9rfAZS"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if device==torch.device('cpu'): print(\"You should probably restart this with a GPU. It will be slow otherwise.\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIw4F-xrpaG5"
      },
      "outputs": [],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ru3B_640jtBT"
      },
      "outputs": [],
      "source": [
        "train_dataset = dataset['train']\n",
        "test_dataset = dataset['test']\n",
        "validation_dataset = dataset['validation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqlzKZRhlh1o"
      },
      "outputs": [],
      "source": [
        "print(train_dataset)\n",
        "print(train_dataset.column_names)  # shows column names\n",
        "print(train_dataset[0])             # shows first sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLTu510fn2RP"
      },
      "outputs": [],
      "source": [
        "sample = train_dataset[30]\n",
        "# Load image (column name might be 'image' or something else)\n",
        "img = sample['image']   # already a PIL Image object if stored as such\n",
        "label = sample['label']\n",
        "\n",
        "# Display\n",
        "plt.imshow(img)\n",
        "plt.title(f\"Label: {label}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwXlyX0Thk-I"
      },
      "outputs": [],
      "source": [
        "num_channels = 1 if img.mode == \"L\" else 3\n",
        "img_height, img_width = img.size[::-1]  # PIL gives (width, height)\n",
        "\n",
        "dataset_info = {\n",
        "    \"num_channels\": 1,\n",
        "    \"img_height\": img_height,\n",
        "    \"img_width\": img_width,\n",
        "    \"num_classes\": len(set(dataset[\"train\"][\"label\"])),  # unique labels\n",
        "    \"class_names\": list(set(dataset[\"train\"][\"label\"]))\n",
        "}\n",
        "\n",
        "print(dataset_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnItvNboWRX2"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 4. Define transforms for CNN\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),      # Resize to fixed size\n",
        "    transforms.Grayscale(num_output_channels=1),  # spectrograms usually grayscale\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])   # normalize [-1,1]\n",
        "])\n",
        "\n",
        "# 5. Wrap HF dataset into PyTorch Dataset\n",
        "class SpectrogramDataset(Dataset):\n",
        "    def __init__(self, hf_dataset, transform=None):\n",
        "        self.dataset = hf_dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.dataset[idx]\n",
        "        img = sample[\"image\"]\n",
        "        label = sample[\"label\"]\n",
        "\n",
        "        # If HF image is stored as file path, open it\n",
        "        if isinstance(img, str):\n",
        "            img = Image.open(img)\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "# 6. Train / Test splits\n",
        "train_dataset1 = SpectrogramDataset(train_dataset, transform=transform)\n",
        "test_dataset1 = SpectrogramDataset(test_dataset, transform=transform)\n",
        "validation_dataset1 = SpectrogramDataset(validation_dataset, transform=transform)\n",
        "\n",
        "# 7. Dataloaders\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset1, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset1, batch_size=batch_size, shuffle=False)\n",
        "validation_loader = DataLoader(validation_dataset1, batch_size=batch_size, shuffle = False)\n",
        "# 8. View a few sample images\n",
        "imgs, labels = next(iter(test_loader))\n",
        "\n",
        "print(f\"Batch shape: {imgs.shape}\")   # [B, C, H, W]\n",
        "print(f\"Labels: {labels[:10]}\")\n",
        "\n",
        "# Un-normalize for display\n",
        "def show_images(imgs, labels, n=6):\n",
        "    imgs = imgs[:n].clone()\n",
        "    labels = labels[:n]\n",
        "    imgs = imgs * 0.5 + 0.5  # unnormalize from [-1,1] to [0,1]\n",
        "\n",
        "    fig, axes = plt.subplots(1, n, figsize=(15, 3))\n",
        "    for i, ax in enumerate(axes):\n",
        "        ax.imshow(imgs[i][0], cmap=\"gray\")\n",
        "        ax.set_title(f\"Label: {labels[i].item()}\")\n",
        "        ax.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "show_images(imgs, labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0uOX46ad9h7"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, test_loader, epochs=50, lr=0.001):\n",
        "    # Initialize wandb\n",
        "    model_name = type(model).__name__\n",
        "    wandb.init(project=f\"convnet_spectrogram\", name=f\"{model_name},relu\", reinit=True)\n",
        "    wandb.config.update({\n",
        "        \"epochs\": epochs,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"learning_rate\": lr,\n",
        "        \"model\": model_name,\n",
        "        \"optimizer\": \"Adam\"\n",
        "    })\n",
        "\n",
        "    # Loss function:\n",
        "    # Note: targets are just class indices (0-9), not one-hot vectors\n",
        "    # nn.CrossEntropyLoss handles one-hot encoding internally for efficiency\n",
        "    criterion = nn.CrossEntropyLoss()   # used for categorical variables, expects raw \"logits\"\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    train_accuracies = []\n",
        "    test_accuracies = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "\n",
        "        # Use tqdm for progress bar\n",
        "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}')\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(pbar):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct_train += pred.eq(target.view_as(pred)).sum().item()\n",
        "            total_train += target.size(0)\n",
        "\n",
        "            # Update progress bar\n",
        "            pbar.set_postfix({\n",
        "                'Loss': f'{loss.item():.4f}',\n",
        "                'Acc': f'{100.*correct_train/total_train:.2f}%'\n",
        "            })\n",
        "\n",
        "        # Calculate epoch metrics\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        train_acc = 100. * correct_train / total_train\n",
        "\n",
        "        # Evaluation phase\n",
        "        model.eval()\n",
        "        test_loss_sum = 0\n",
        "        correct_test = 0\n",
        "        total_test = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                output = model(data)\n",
        "                test_loss_sum += criterion(output, target).item()\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                correct_test += pred.eq(target.view_as(pred)).sum().item()\n",
        "                total_test += target.size(0)\n",
        "\n",
        "        test_loss = test_loss_sum / len(test_loader)\n",
        "        test_acc = 100.0 * correct_test / total_test\n",
        "\n",
        "        # Store metrics\n",
        "        train_losses.append(epoch_loss)\n",
        "        test_losses.append(test_loss)\n",
        "        train_accuracies.append(train_acc)\n",
        "        test_accuracies.append(test_acc)\n",
        "\n",
        "        # Log to wandb\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"train_loss\": epoch_loss,\n",
        "            \"test_loss\": test_loss,\n",
        "            \"train_accuracy\": train_acc,\n",
        "            \"test_accuracy\": test_acc\n",
        "        })\n",
        "\n",
        "        print(f'Epoch {epoch+1}: Train Loss: {epoch_loss:.4f}, Test Loss: {test_loss:.4f} Train Acc: {train_acc:.2f}%, Test Acc: {test_acc:.2f}%')\n",
        "\n",
        "    wandb.finish()\n",
        "\n",
        "    return {\n",
        "        'train_losses': train_losses,\n",
        "        'train_accuracies': train_accuracies,\n",
        "        'test_accuracies': test_accuracies,\n",
        "        'final_test_acc': test_acc\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3o9ruvYGcrvb"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, dataset_info, base_channels=32, channel_mult=2, n_conv_layers=4):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # Build conv layers dynamically\n",
        "        self.conv_layers = nn.ModuleList()\n",
        "        in_channels = dataset_info['num_channels']\n",
        "        for i in range(n_conv_layers):\n",
        "            out_channels = base_channels * (channel_mult ** i)\n",
        "            self.conv_layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1))\n",
        "            in_channels = out_channels\n",
        "\n",
        "        self.activation = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1) # put near end: yields one value per channel\n",
        "\n",
        "        # Final channels after all conv layers\n",
        "        final_channels = base_channels * (channel_mult ** (n_conv_layers - 1))\n",
        "        self.fc = nn.Linear(final_channels, dataset_info['num_classes'])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for conv_layer in self.conv_layers:\n",
        "            x = self.activation(conv_layer(x))\n",
        "            x = self.dropout1(x)\n",
        "        x = self.global_avg_pool(x)  # one value per channel\n",
        "        return self.fc(  x.flatten(start_dim=1) )  # flatten and run through linear layer\n",
        "\n",
        "\n",
        "\n",
        "cnn_model = CNN(dataset_info).to(device)\n",
        "print(f\"CNN Model Parameters: {sum(p.numel() for p in cnn_model.parameters()):,}\")\n",
        "\n",
        "# quick test to make sure the forward() runs w/o errors:\n",
        "rnd_batch = torch.randn([128,dataset_info['num_channels'], dataset_info['img_height'], dataset_info['img_width']]).to(device)\n",
        "result = cnn_model(rnd_batch)\n",
        "del rnd_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyEp8I4hhuWC"
      },
      "outputs": [],
      "source": [
        "print(\"\\nTraining CNN Model...\")\n",
        "start_time = time.time()\n",
        "cnn_results = train_model(cnn_model, train_loader, validation_loader, epochs=50)\n",
        "cnn_training_time = time.time() - start_time\n",
        "print(f\"CNN Training completed in {cnn_training_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzMlkh-ygWPi"
      },
      "outputs": [],
      "source": [
        "#\n",
        "#THIS IS THE FINAL MODEL USING THE VALIDATION SET WITH NO DROPOUTS AND DOES NOT CALC GRADIENTS.\n",
        "#\n",
        "# --- Final Evaluation on Test Set ---\n",
        "\n",
        "# Ensure the model is on the correct device and in evaluation mode\n",
        "cnn_model.to(device)\n",
        "cnn_model.eval()\n",
        "\n",
        "# We need the same loss function as before\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Initialize variables to track performance\n",
        "test_loss = 0.0\n",
        "correct_test = 0\n",
        "total_test = 0\n",
        "\n",
        "# Disable gradient calculations for efficiency\n",
        "with torch.no_grad():\n",
        "    # Loop through the test data\n",
        "    for data, target in test_loader:\n",
        "        # Move data to the device (GPU/CPU)\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # Get model predictions\n",
        "        output = cnn_model(data)\n",
        "\n",
        "        # Calculate the loss for this batch\n",
        "        loss = criterion(output, target)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        # Get the class with the highest probability\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "\n",
        "        # Count correct predictions\n",
        "        correct_test += pred.eq(target.view_as(pred)).sum().item()\n",
        "        total_test += target.size(0)\n",
        "\n",
        "# Calculate final accuracy and loss\n",
        "final_accuracy = 100. * correct_test / total_test\n",
        "avg_loss = test_loss / len(test_loader)\n",
        "\n",
        "print(f\"\\n--- Final Test Results ---\")\n",
        "print(f\"Average Loss: {avg_loss:.4f}\")\n",
        "print(f\"Accuracy: {correct_test}/{total_test} ({final_accuracy:.2f}%)\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}